{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7acc61-cb5e-4db7-90fc-5269a33c3782",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ignore loguru logs from backend\n",
    "logger.remove()  \n",
    "logger.add(lambda msg: None, level=\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54daefc3-0f2c-45d2-85b6-6210a7ad2d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project directory to the path\n",
    "backend_path = os.path.abspath('../')\n",
    "if backend_path not in sys.path:\n",
    "    sys.path.append(backend_path)\n",
    "\n",
    "from backend.causal_models.factory import CausalLMFactory\n",
    "from backend.schemas import SearchResult, GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a95728-e6a6-43ef-9d3e-b98afc74ccba",
   "metadata": {},
   "source": [
    "# Building dataset from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511a8b1-e563-49ff-8f69-6ae28e9ac86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataset import dataset\n",
    "from PIL import Image\n",
    "\n",
    "artificial_dataset = []\n",
    "\n",
    "for sample in dataset:\n",
    "    artificial_sample = []\n",
    "    for search_result in sample:\n",
    "        if search_result[\"image\"]:\n",
    "            img = Image.open(search_result[\"image\"])\n",
    "        artificial_sample.append(\n",
    "            SearchResult(\n",
    "                text=search_result[\"text\"],\n",
    "                document_name=search_result[\"document_name\"],\n",
    "                image=img\n",
    "            )\n",
    "        )\n",
    "    artificial_dataset.append(artificial_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73156a14-92a6-4471-b136-a812c16d15ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What was the trend or progression of Arctic sea ice cover in the period between 1991-2020?\",\n",
    "    \"Which AI Model did perform best in forecasting certain weather situations?\",\n",
    "    \"How many countries build MHEWS in the year 2020?\",\n",
    "    \"What are the estimated ozone exposure levels in South Asia? (Provide specific numbers if possible.)\",\n",
    "    \"Where were the most Meteorological event recorded? (Meteorological event: storm, winter storm,severe weather, hail, tornado, local storm) Give numbers if possible.\",\n",
    "    \"Around what time of year is the ozone hole at its largest?\",\n",
    "    \"What was the last measured sea level in mm approximately?\",\n",
    "    \"In which year was the long-term average of the global combined surface air temperature over land and sea crossed?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533016a-7e00-4820-a517-0ffba6fa1a71",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dcdf80-cda6-4ad0-9e82-5ed146615630",
   "metadata": {},
   "source": [
    "## Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef845066-d996-4acc-978c-a095eb494d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "            max_new_tokens=150,\n",
    "            no_repeat_ngram_size=3,\n",
    "            temperature=1,\n",
    "            top_k=90,\n",
    "            num_beams=1,\n",
    "            do_sample=False,\n",
    "            length_penalty=-0.7,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef26dba-73fe-4928-9fbd-79f00a801b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "template_dir = \"./prompt_templates\"\n",
    "\n",
    "# Load the template from the file system\n",
    "env = Environment(loader=FileSystemLoader(template_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be2bdc-d467-4720-adce-bbd37067a3d3",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2631e9-0d10-450a-9c61-581c098f0b63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load prompt template\n",
    "template = env.get_template('language_prompt.j2')\n",
    "\n",
    "# Init model\n",
    "model = CausalLMFactory.get_model(\"HuggingFaceH4/zephyr-7b-beta\")\n",
    "model.set_prompt_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfc6ae-b88b-46c8-8d03-2f9b6e2762bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "language_results = []\n",
    "\n",
    "# Inference loop\n",
    "for question, sample in zip(questions, artificial_dataset):\n",
    "    context = \"\\n\".join([s.text for s in sample])\n",
    "    answer = model.generate(question, sample, **generation_config.dict())\n",
    "    language_results.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"context\": context\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304fb1f-7eff-4dc7-ad63-1ca200df2f21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame(language_results)\n",
    "results.to_csv(\"language_results.csv\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4d13e3-12a6-4539-a215-c0500679cde4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Clean up\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c9edc-4f01-49d4-98d5-c0d8985f35e5",
   "metadata": {},
   "source": [
    "## Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6f90f-26e2-4aa2-a378-e34a80d0390b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load prompt template\n",
    "template = env.get_template('multimodal_prompt.j2')\n",
    "\n",
    "# Init model\n",
    "model = CausalLMFactory.get_model(\"HuggingFaceM4/idefics2-8b-chatty\")\n",
    "model.set_prompt_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6820303-d346-45a3-b717-8f99a8259000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "multimodal_results = []\n",
    "\n",
    "# Inference loop\n",
    "for question, sample in zip(questions, artificial_dataset):\n",
    "    context = \"\\n\".join([s.text for s in sample])\n",
    "    answer = model.generate(question, sample, **generation_config.dict())\n",
    "    multimodal_results.append(\n",
    "        {\n",
    "            \"question\": question,\n",
    "            \"answer\": answer,\n",
    "            \"context\": context\n",
    "        }\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b60fac-d845-4e2c-9b0c-43365c3e7e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(multimodal_results)\n",
    "results.to_csv(\"multimodal_results.csv\")\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b83905-3cf2-435e-a179-77e10891e506",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750bc6f-a42d-4c27-b26a-7bac25c8b67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.evaluation import load_evaluator\n",
    "import os\n",
    "\n",
    "open_ai_auth = os.getenv(\"OPEN_AI\")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"SECRET\"\n",
    "\n",
    "evaluation_llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "evaluator = load_evaluator(\"labeled_criteria\", criteria=\"correctness\", llm=evaluation_llm,requires_reference=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ec0a1-a5b5-4e01-9eb9-d8b04053c2b8",
   "metadata": {},
   "source": [
    "## Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075167ac-240c-4680-919b-05c1e5b06cbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "language_results = pd.read_csv(\"language_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bb798-952c-41c8-bc05-2b98ca62ec26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt_language_evaluation = []\n",
    "\n",
    "for (i, (_, question, answer, context)) in language_results.iterrows():\n",
    "    eval_result = evaluator.evaluate_strings(\n",
    "                prediction=answer,\n",
    "                input=question,\n",
    "                reference=context\n",
    "            )\n",
    "    gpt_language_evaluation.append(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4367e6b6-7009-4851-8ce5-7b7273988384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(gpt_language_evaluation)\n",
    "res.to_csv(\"gpt_evaluation.csv\")\n",
    "res.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
